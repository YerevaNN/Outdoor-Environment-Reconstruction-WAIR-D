_target_: src.networks.MLPViTUPerNet

num_classes: 1

mlp_input_dim: 5

v_num_channels: 3
v_patch_size: 16
v_hidden_size: 768
v_num_hidden_layers: 12
v_num_attention_heads: 12
res_hidden_states: [ 1, 5, 9, 13 ]
up_pool_scales: [ 1, 2, 4, 7 ]
pretrained: openai/clip-vit-base-patch16