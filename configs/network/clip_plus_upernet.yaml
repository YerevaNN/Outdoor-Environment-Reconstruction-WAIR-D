_target_: src.networks.CLIPPlusUPerNet

num_classes: 1
image_size: 224

mlp_input_dim: 20
min_mlp_tokens: 10
num_channels: 150

v_num_channels: 3
v_patch_size: 16
v_hidden_size: 768
v_num_hidden_layers: 12
v_num_attention_heads: 12
mixer_out: null
res_hidden_states: null
up_pool_scales: [ 1, 2, 4, 7 ]
neck_scales: null
neck_size: [ 96, 192, 384, 768 ]
pretrained: openai/clip-vit-base-patch16

reconstruction: True