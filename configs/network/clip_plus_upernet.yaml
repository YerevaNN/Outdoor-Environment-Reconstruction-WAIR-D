_target_: src.networks.CLIPPlusUPerNet

num_classes: 1
image_size: 224

mlp_input_dim: 5
min_mlp_tokens: 1
num_channels: 3

v_num_channels: 3
v_patch_size: 16
v_hidden_size: 768
v_num_hidden_layers: 12
v_num_attention_heads: 12
mixer_out: null
res_hidden_states: [ 1, 5, 9, 13 ]
up_pool_scales: [ 1, 2, 4, 7 ]
neck_scales: [ 16, 8, 2, 1 ]
neck_size: [ 96, 192, 384, 768 ]
pretrained: openai/clip-vit-base-patch16

reconstruction: False